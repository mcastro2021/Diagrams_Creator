#!/usr/bin/env python3
"""
Script para instalar y configurar Ollama
"""

import os
import sys
import subprocess
import platform
import requests
import time

def detect_os():
    """Detectar sistema operativo"""
    system = platform.system().lower()
    if system == "windows":
        return "windows"
    elif system == "darwin":
        return "macos"
    elif system == "linux":
        return "linux"
    else:
        return "unknown"

def install_ollama_windows():
    """Instalar Ollama en Windows"""
    print("ü™ü Instalando Ollama para Windows...")
    print("\nüìù Instrucciones para Windows:")
    print("1. Ve a: https://ollama.ai/download")
    print("2. Descarga 'Ollama for Windows'")
    print("3. Ejecuta el instalador")
    print("4. Reinicia tu terminal")
    print("5. Ejecuta: ollama pull llama3.2")
    
    input("\nPresiona Enter cuando hayas completado la instalaci√≥n...")
    return test_ollama()

def install_ollama_macos():
    """Instalar Ollama en macOS"""
    print("üçé Instalando Ollama para macOS...")
    
    # Verificar si Homebrew est√° instalado
    try:
        subprocess.run(["brew", "--version"], check=True, capture_output=True)
        print("‚úÖ Homebrew detectado")
        
        # Instalar con Homebrew
        print("üì¶ Instalando Ollama con Homebrew...")
        subprocess.run(["brew", "install", "ollama"], check=True)
        
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("‚ö†Ô∏è  Homebrew no encontrado. Instalaci√≥n manual:")
        print("1. Ve a: https://ollama.ai/download")
        print("2. Descarga 'Ollama for macOS'")
        print("3. Arrastra Ollama a Applications")
        print("4. Abre Terminal y ejecuta: ollama pull llama3.2")
        
        input("\nPresiona Enter cuando hayas completado la instalaci√≥n...")
    
    return test_ollama()

def install_ollama_linux():
    """Instalar Ollama en Linux"""
    print("üêß Instalando Ollama para Linux...")
    
    try:
        # Descargar e instalar Ollama
        print("üì• Descargando Ollama...")
        subprocess.run([
            "curl", "-fsSL", "https://ollama.ai/install.sh"
        ], check=True, stdout=subprocess.PIPE)
        
        print("üîß Instalando Ollama...")
        install_cmd = "curl -fsSL https://ollama.ai/install.sh | sh"
        subprocess.run(install_cmd, shell=True, check=True)
        
        print("‚úÖ Ollama instalado")
        
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Error instalando Ollama: {e}")
        print("\nüìù Instalaci√≥n manual:")
        print("1. Ejecuta: curl -fsSL https://ollama.ai/install.sh | sh")
        print("2. O ve a: https://ollama.ai/download")
        
        input("\nPresiona Enter cuando hayas completado la instalaci√≥n...")
    
    return test_ollama()

def test_ollama():
    """Probar si Ollama est√° funcionando"""
    print("\nüß™ Probando Ollama...")
    
    try:
        # Probar comando ollama
        result = subprocess.run(["ollama", "--version"], 
                              capture_output=True, text=True, timeout=10)
        
        if result.returncode == 0:
            print(f"‚úÖ Ollama instalado: {result.stdout.strip()}")
            return True
        else:
            print("‚ùå Ollama no responde correctamente")
            return False
            
    except FileNotFoundError:
        print("‚ùå Comando 'ollama' no encontrado")
        return False
    except subprocess.TimeoutExpired:
        print("‚ùå Ollama no responde (timeout)")
        return False

def test_ollama_api():
    """Probar API de Ollama"""
    print("üåê Probando API de Ollama...")
    
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            print("‚úÖ API de Ollama funcionando")
            return True
        else:
            print(f"‚ùå API responde con c√≥digo: {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print("‚ùå No se puede conectar a la API de Ollama")
        print("üí° Aseg√∫rate de que Ollama est√© ejecut√°ndose")
        return False
    except requests.exceptions.Timeout:
        print("‚ùå Timeout conectando a la API")
        return False

def download_model(model_name="llama3.2"):
    """Descargar modelo de IA"""
    print(f"\nüì• Descargando modelo {model_name}...")
    print("‚ö†Ô∏è  Esto puede tomar varios minutos dependiendo de tu conexi√≥n")
    
    try:
        # Ejecutar ollama pull
        process = subprocess.Popen(
            ["ollama", "pull", model_name],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        print("üìä Descargando... (esto puede tomar tiempo)")
        
        # Mostrar progreso
        while True:
            output = process.stdout.readline()
            if output == '' and process.poll() is not None:
                break
            if output:
                print(f"   {output.strip()}")
        
        if process.returncode == 0:
            print(f"‚úÖ Modelo {model_name} descargado exitosamente")
            return True
        else:
            error = process.stderr.read()
            print(f"‚ùå Error descargando modelo: {error}")
            return False
            
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Error ejecutando ollama pull: {e}")
        return False

def update_env_file():
    """Actualizar archivo .env"""
    print("\nüìù Actualizando configuraci√≥n...")
    
    env_file = ".env"
    
    # Leer archivo actual
    if os.path.exists(env_file):
        with open(env_file, 'r') as f:
            content = f.read()
    else:
        # Copiar desde ejemplo
        if os.path.exists("env_example.txt"):
            with open("env_example.txt", 'r') as f:
                content = f.read()
        else:
            content = ""
    
    # Actualizar AI_PROVIDER
    if "AI_PROVIDER=" in content:
        content = content.replace("AI_PROVIDER=openai", "AI_PROVIDER=ollama")
        content = content.replace("AI_PROVIDER=groq", "AI_PROVIDER=ollama")
        content = content.replace("AI_PROVIDER=huggingface", "AI_PROVIDER=ollama")
    else:
        content = "AI_PROVIDER=ollama\n" + content
    
    # Guardar archivo
    with open(env_file, 'w') as f:
        f.write(content)
    
    print("‚úÖ Archivo .env actualizado para usar Ollama")

def main():
    """Funci√≥n principal"""
    print("üöÄ Instalador de Ollama para Diagrams Creator")
    print("=" * 60)
    
    # Detectar OS
    os_type = detect_os()
    print(f"üñ•Ô∏è  Sistema operativo detectado: {os_type}")
    
    if os_type == "unknown":
        print("‚ùå Sistema operativo no soportado")
        print("Visita https://ollama.ai/download para instalaci√≥n manual")
        return
    
    # Verificar si ya est√° instalado
    if test_ollama():
        print("‚úÖ Ollama ya est√° instalado")
        
        # Verificar API
        if test_ollama_api():
            print("‚úÖ Todo listo para usar")
        else:
            print("‚ö†Ô∏è  Ollama instalado pero API no responde")
            print("üí° Intenta ejecutar: ollama serve")
    else:
        # Instalar seg√∫n OS
        print(f"\nüì¶ Instalando Ollama para {os_type}...")
        
        if os_type == "windows":
            success = install_ollama_windows()
        elif os_type == "macos":
            success = install_ollama_macos()
        elif os_type == "linux":
            success = install_ollama_linux()
        
        if not success:
            print("‚ùå Instalaci√≥n fallida")
            return
    
    # Descargar modelo
    print("\nü§ñ Configurando modelo de IA...")
    
    # Listar modelos disponibles
    try:
        result = subprocess.run(["ollama", "list"], 
                              capture_output=True, text=True, timeout=10)
        
        if "llama3.2" in result.stdout:
            print("‚úÖ Modelo llama3.2 ya est√° disponible")
        else:
            if download_model("llama3.2"):
                print("‚úÖ Modelo descargado exitosamente")
            else:
                print("‚ö†Ô∏è  Error descargando modelo")
                print("üí° Puedes intentar manualmente: ollama pull llama3.2")
    
    except Exception as e:
        print(f"‚ö†Ô∏è  Error verificando modelos: {e}")
    
    # Actualizar configuraci√≥n
    update_env_file()
    
    # Instrucciones finales
    print("\nüéâ ¬°Instalaci√≥n completada!")
    print("=" * 60)
    print("üìã Siguientes pasos:")
    print("1. Reinicia tu aplicaci√≥n: python start_app.py")
    print("2. La aplicaci√≥n usar√° Ollama autom√°ticamente")
    print("3. ¬°Disfruta de IA gratuita e ilimitada!")
    
    print("\nüí° Comandos √∫tiles:")
    print("   ollama list          - Ver modelos instalados")
    print("   ollama pull llama3.2 - Descargar modelo")
    print("   ollama serve         - Iniciar servidor")
    
    print("\nüîó M√°s informaci√≥n:")
    print("   https://ollama.ai/library - M√°s modelos")
    print("   https://ollama.ai/docs   - Documentaci√≥n")

if __name__ == '__main__':
    main()
